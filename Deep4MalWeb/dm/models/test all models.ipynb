{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pefile\n",
    "from capstone import *\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import os.path\n",
    "from keras.models import load_model\n",
    "from os import listdir\n",
    "import csv\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grams_extractor(file_path, grams, size=4):\n",
    "    with open(file_path, 'rb') as fp:\n",
    "        freq = {}\n",
    "        for g in grams:\n",
    "            freq[g] = 0\n",
    "        chunk = fp.read(size).hex()\n",
    "        if chunk in grams:\n",
    "            freq[chunk] = 1\n",
    "        while chunk != '':\n",
    "            chunk = fp.read(size).hex()\n",
    "            try:\n",
    "                freq[chunk] += 1\n",
    "            except:\n",
    "                pass\n",
    "    return freq\n",
    "\n",
    "\n",
    "def grams_rf(freq):\n",
    "    summ = 0\n",
    "    for g in freq:\n",
    "        summ += freq[g]\n",
    "    for g in freq:\n",
    "        freq[g] = freq[g] / summ\n",
    "    return freq\n",
    "\n",
    "\n",
    "def grams_row(freq, grams):\n",
    "    row = []\n",
    "    for g in grams:\n",
    "        row.append(freq[g])\n",
    "    return row\n",
    "\n",
    "\n",
    "def normalized_row(row):\n",
    "    scaler = MinMaxScaler()\n",
    "    norm_row = scaler.fit_transform(np.array(row).reshape(-1, 1))\n",
    "    return norm_row\n",
    "\n",
    "\n",
    "def extract_imports(file_path, dlls, functions):\n",
    "    dlls_used = {}\n",
    "    functions_used = {}\n",
    "    for dll in dlls:\n",
    "        dlls_used[dll] = 0\n",
    "    for function in functions:\n",
    "        functions_used[function] = 0\n",
    "    try:\n",
    "        exe = pefile.PE(file_path)\n",
    "    except:\n",
    "        return 'parsing error'\n",
    "    try:\n",
    "        for entry in exe.DIRECTORY_ENTRY_IMPORT:\n",
    "            dll = entry.dll.decode('utf-8').lower()\n",
    "            try:\n",
    "                dlls_used[dll] = 1\n",
    "            except:\n",
    "                pass\n",
    "            for func in entry.imports:\n",
    "                if func.name is not None:\n",
    "                    func_name = func.name.decode('utf-8').lower()\n",
    "                    if dll+func_name in functions:\n",
    "                        functions_used[dll+func_name] = 1\n",
    "                else:\n",
    "                    func_ordinal = str(func.ordinal)\n",
    "                    if dll+func_ordinal in functions:\n",
    "                        functions_used[dll+func_ordinal] = 1\n",
    "        return list(functions_used.values()) + list(dlls_used.values())\n",
    "    except:\n",
    "        return 'no imports'\n",
    "\n",
    "\n",
    "def imports_json(file_path):\n",
    "    imports = {}\n",
    "    try:\n",
    "        exe = pefile.PE(file_path)\n",
    "    except:\n",
    "        return 'parsing error'\n",
    "    try:\n",
    "        for entry in exe.DIRECTORY_ENTRY_IMPORT:\n",
    "            dll = entry.dll.decode('utf-8').lower()\n",
    "            imports[dll] = []\n",
    "            for func in entry.imports:\n",
    "                if func.name is not None:\n",
    "                    func_name = func.name.decode('utf-8').lower()\n",
    "                    imports[dll].append(func_name)\n",
    "                else:\n",
    "                    func_ordinal = str(func.ordinal)\n",
    "                    imports[dll].append(func_ordinal)\n",
    "        return imports\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "\n",
    "\n",
    "def get_main_code_section(sections, base_of_code):\n",
    "    addresses = []\n",
    "    for section in sections:\n",
    "        addresses.append(section.VirtualAddress)\n",
    "    if base_of_code in addresses:\n",
    "        # if sections[addresses.index(base_of_code)].Characteristics == int(0x60000020):\n",
    "        if 1 == 1:\n",
    "            return sections[addresses.index(base_of_code)]\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        addresses.append(base_of_code)\n",
    "        addresses.sort()\n",
    "        if addresses.index(base_of_code) != 0:\n",
    "            # if sections[addresses.index(base_of_code)-1].Characteristics == int(0x60000020):\n",
    "            if 1 == 1:\n",
    "                return sections[addresses.index(base_of_code) - 1]\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "\n",
    "def get_instruction_group(inst):\n",
    "    inst_groups = {\n",
    "        # Conditional Data Transfer\n",
    "        'cdt': ['cmove', 'cmovz', 'cmovne', 'cmovnz', 'cmova', 'cmovnbe', 'cmovae', 'cmovnb', 'cmovb',\n",
    "                'cmovnae', 'cmovbe', 'cmovna', 'cmovg',\n",
    "                'cmovnle', 'cmovge', 'cmovnl', 'cmovl', 'cmovnge', 'cmovle', 'cmovng',\n",
    "                'cmovc', 'cmovnc', 'cmovo', 'cmovno', 'cmovs', 'cmovns', 'cmovp', 'cmovpe',\n",
    "                'cmovnp', 'cmovpo', ],\n",
    "        # Unconditianl Data Transfer\n",
    "        'udt': ['mov', 'xchg', 'bswap', 'movsx', 'movzx', 'movlps', 'movqda', 'lock xchg'],\n",
    "        # Stack Data Transfer\n",
    "        'sdt': ['push', 'pop', 'pusha', 'pushad', 'popa', 'popad', 'popal', 'pushal'],\n",
    "        'adt': ['xadd'],\n",
    "\n",
    "        # Compared Data Transfer\n",
    "        'cmpdt': ['cmpxchg', 'cmpxchg8b', ],\n",
    "        # Converting\n",
    "        'cvt': ['cwd', 'cdq', 'cbw', 'cwde'],\n",
    "        # Binary Arithmetic Instructions\n",
    "        'bai': ['adcx', 'adox', 'add', 'adc', 'sub', 'sbb', 'imul', 'imulb', 'imulw', 'imull',\n",
    "                'mul', 'mulb', 'mulw', 'mull', 'idiv', 'idivb', 'idivw', 'idivl',\n",
    "                'div', 'inc', 'dec', 'neg', 'cmp', 'addb', 'addw', 'addl', 'adcb',\n",
    "                'adcw', 'adcl', 'subb', 'subw', 'subl', 'sbbb', 'sbbw', 'sbbl',\n",
    "                'cmpb', 'cmpw', 'cmpl', 'incb', 'incw', 'incl', 'decb', 'decw',\n",
    "                'decl', 'negb', 'negw', 'negl', 'lock add', 'lock adc', 'lock sbb',\n",
    "                'lock sub', 'lock neg', 'lock inc', 'lock dec'],\n",
    "        # Integer Arithmetic Instructions\n",
    "        'iai': ['fiadd', 'fiaddr', 'ficom', 'fidiv', 'fisub', 'fimul', 'ficomp', 'fisubr', 'fidivr', 'fimulr'],\n",
    "        # Decimal Arithmetic Instructions\n",
    "        'dai': ['daa', 'das', 'aaa', 'aas', 'aam', 'aad', ],\n",
    "        # Flaot Arithmetic Instructions\n",
    "        'fai': ['fabs', 'fadd', 'faddp', 'fchs', 'fdiv', 'fdivp', 'fdivr', 'fdivrp', 'fiadd',\n",
    "                'fidiv', 'fidivr', 'fimul',\n",
    "                'fisub', 'fisubr', 'fmul', 'fmulp', 'fprem', 'fprem1', 'frndint', 'fscale', 'fsqrt',\n",
    "                'fsub', 'fsubp',\n",
    "                'fsubr', 'fsubrp', 'fxtract'],\n",
    "        # Float Comparison Instructions\n",
    "        'fci': ['fcom', 'fcomi', 'fcomip', 'fcomp', 'fcompp', 'ftst', 'fucom',\n",
    "                'fucomi', 'fucomip', 'fucomp', 'fucompp', 'fxam'],\n",
    "        # Stack Arithmetic Instructions\n",
    "        'sai': ['fsqrt', 'fscale', 'fprem', 'frndint', 'fxtract', 'fabs', 'fchs', ],\n",
    "        # Logical Instructions\n",
    "        'li': ['and', 'andb', 'andw', 'andl', 'or', 'orb', 'orw', 'orl', 'xor',\n",
    "               'xorb', 'xorw', 'xorl', 'not', 'notb', 'notw', 'notl', 'lock or',\n",
    "               'lock and', 'lock xor', 'lock not', ],\n",
    "        # Shift Rotate Instructions\n",
    "        'sri': ['sar', 'shr', 'sal', 'shl', 'shrd', 'shld', 'ror', 'rol', 'rcr', 'rcl',\n",
    "                'sarb', 'sarw', 'sarl', 'salb', 'salw', 'sall', 'shrb', 'shrw', 'shrl',\n",
    "                'shld', 'shldw', 'shldl', 'shrd', 'shrdw', 'shrdl', ],\n",
    "        # Bit Instructions\n",
    "        'bii': ['bt', 'bts', 'btr', 'btc', 'bsf', 'bsr', 'lock bt', 'lock bts',\n",
    "                'lock btr', 'lockbtc'],\n",
    "        # Byte Instructions\n",
    "        'byi': ['sete', 'setz', 'setne', 'setnz', 'seta', 'setnbe', 'setae', 'setnb', 'setnc', 'setb', 'setnae',\n",
    "                'setc', 'setbe', 'setna', 'setg', 'setnle', 'setge', 'setnl', 'setl', 'setnge', 'setle', 'setng',\n",
    "                'sets', 'setns', 'seto', 'setno', 'setpe', 'setp', 'setpo', 'setnp', 'test', 'testb',\n",
    "                'testw', 'testl', 'crc32', 'popcnt', ],\n",
    "        # Conditional Jumping\n",
    "        'cj': ['je', 'jz', 'jnz', 'jnz', 'ja', 'jnbe', 'jae', 'jnb', 'jb', 'jnae', 'jbe', 'jna', 'jg',\n",
    "               'jnle', 'jge', 'jnl', 'jl', 'jnge', 'jle', 'jng', 'jc', 'jnc', 'jo', 'jno', 'js', 'jns',\n",
    "               'jpo', 'jnp', 'jpe', 'jp', 'jcxz', 'jecxz', 'loopz', 'loope', 'loopnz', 'loopne', 'into',\n",
    "               'jne'],\n",
    "        # Unconditional Jumping/Looping\n",
    "        'uj': ['jmp', 'loop', 'call', 'enter', 'leave', 'lcall', 'acall', 'ljmp', ],\n",
    "        # Interruptions\n",
    "        'int': ['ret', 'iret', 'retn', 'int', 'retf', 'hlt', 'iretd', ],\n",
    "        # Strings Instructions\n",
    "        'si': ['movs', 'movsb', 'movsw', 'movsd', 'cmps', 'cmpsb', 'cmpsw', 'cmpsd', 'scas',\n",
    "               'scasb', 'scasw', 'scasd', 'lods', 'lodsb', 'lodsw', 'lodsd', 'rep', 'repe',\n",
    "               'repz', 'repne', 'repnz', 'stos', 'stosd', 'stosb', 'stosw', 'stosl', ],\n",
    "        # I/O Instructions\n",
    "        'io': ['in', 'out', 'ins', 'insb', 'insw', 'insd', 'outs', 'outsb', 'outsw', 'outsd',\n",
    "               'inb', 'inw', 'insl', 'outw', 'outsl', 'outl', ],\n",
    "        # Flags\n",
    "        'flg': ['stc', 'clc', 'cmc', 'cld', 'std', 'lahf', 'sahf', 'pushf', 'pushfd',\n",
    "                'popf', 'popfd', 'sti', 'cli', 'popfw', 'popfl', 'pushfw', 'pushfl', 'salc'],\n",
    "        # Segment Register Instructions\n",
    "        'seg': ['lds', 'les', 'lfs', 'lgs', 'lss', ],\n",
    "        #\n",
    "        'misc': ['lea', 'nop', 'ud', 'xlat', 'xlatb', 'cpuid', 'prefetchw', 'prefetchwt',\n",
    "                 'clflush', 'clflushopt', ],\n",
    "\n",
    "        'sr': ['xsave', 'xsavec', 'xsaveopt', 'xrstor', 'xgetbv', ],\n",
    "\n",
    "        'rng': ['rdrand', 'rdseed'],\n",
    "\n",
    "        'arr': ['bound', 'boundb', 'boundw', 'boundl'],\n",
    "\n",
    "        'pmi': ['sldt', 'str', 'lldt', 'ltr', 'verr', 'verw', 'sgdt', 'sidt',\n",
    "                'smsw', 'lmsw', 'lar', 'lsl', 'clts', 'arpl', 'lgdt', 'lidt', ],\n",
    "\n",
    "        'pci': ['frstor', 'finitfninit', 'finit', 'fnop', 'fsave', 'fnsave', 'fstcw',\n",
    "                'fnstcw', 'fstenv', 'fnstenv', 'fstsw', 'fnstsw', 'fwait', 'wait',\n",
    "                'fclex', 'fnclex', 'fdecstp', 'ffree', 'fincstp', 'pause', 'fclex',\n",
    "                'fdecstp', 'ffree', 'fincstp', 'finit', 'fldcw', 'fldenv',\n",
    "                'fnclex', 'fninit', 'fnop', 'fnsave', 'fnstcw', 'fnstenv',\n",
    "                'fnstsw', 'frstor', 'fsave', 'fstcw', 'fstenv', 'fstsw', 'fwait',\n",
    "                'rdtsc', 'fxrstor', 'fxsave', 'invd', 'winvd', ],\n",
    "        # MMX Data Transfer\n",
    "        'mmxt': ['movd', 'movq'],\n",
    "        # MMX Conversion\n",
    "        'mmxc': ['packssdw', 'packsswb', 'packuswb', 'punpckhbw', 'punpckhdq',\n",
    "                 'punpckhwd', 'punpcklbw', 'punpckldq', 'punpcklwd'],\n",
    "        # MMX Arithmetic Instuctions\n",
    "        'mmxa': ['paddb', 'paddd', 'paddsb', 'paddsw', 'paddusb', 'paddusw', 'paddw', 'pmaddwd', 'pmulhw',\n",
    "                 'pmullw', 'psubb', 'psubd', 'psubsb', 'psubsw', 'psubusb', 'psubusw', 'psubw'],\n",
    "        # MMX Comparision\n",
    "        'mmxcmp': ['pcmpeqd', 'pcmpeqb', 'pcmpeqw', 'pcmpgtb', 'pcmpgtd', 'pcmpgtw'],\n",
    "        # MMX Logical\n",
    "        'mmxl': ['pand', 'pandn', 'por', 'pxor'],\n",
    "        # MMX Shift Rotate Instuctions\n",
    "        'mmxsr': ['pslld', 'psllq', 'psllw', 'psrad', 'psraw', 'psrld', 'psrlq', 'psrlw'],\n",
    "        # MMX State Management\n",
    "        'mmxsm': ['emms'],\n",
    "        # SSE Data Transfer\n",
    "        'sset': ['movaps', 'movhlps', 'movhps', 'movlhps', 'movlps', 'movmskps', 'movss', 'movups'],\n",
    "        # SSE Arithmetic Instructions\n",
    "        'ssea': ['addps', 'addss', 'divps', 'divss', 'maxps', 'maxss', 'minps', 'minss', 'mulps',\n",
    "                 'mulss', 'rcpps', 'rcpss', 'rsqrtps', 'rsqrtss', 'sqrtps', 'sqrtss', 'subps', 'subss'],\n",
    "        # SSE Comparision\n",
    "        'ssecmp': ['cmpps', 'cmpss', 'comiss', 'ucomiss', ],\n",
    "        # SSE Logical\n",
    "        'ssel': ['andnps', 'andps', 'orps', 'xorps'],\n",
    "        # SSE Shuffle Unpack\n",
    "        'ssesu': ['shufps', 'unpckhps', 'unpcklps'],\n",
    "        # SSE Convertion\n",
    "        'ssecvt': ['cvtpi2ps', 'cvtps2pi', 'cvtsi2ss', 'cvtss2si', 'cvttps2pi', 'cvttss2si'],\n",
    "        # SSE\n",
    "\n",
    "        # Floating Data Transfer\n",
    "        'fdt': ['fbld', 'fbstp', 'fcmovb', 'fcmovbe', 'fcmove', 'fcmovnb', 'fcmovnbe', 'fcmovne',\n",
    "                'fcmovnu', 'fcmovu', 'fild', 'fist', 'fistp', 'fld', 'fst', 'fstp', 'fxch', 'fisttp', ],\n",
    "        # Flaot Transcedental\n",
    "        'ftrdt': ['f2xm1', 'fcos', 'fpatan', 'fptan', 'fsin', 'fsincos', 'fyl2x', 'fyl2xp1'],\n",
    "        # Float Load constant\n",
    "        'flc': ['fld1', 'fldl2e', 'fldl2t', 'fldlg2', 'fldln2', 'fldpi', 'fldz'],\n",
    "\n",
    "        'tse': ['xabort', 'xbegin', 'xbeginl', 'xbeginw', 'xend', 'xtest'],\n",
    "\n",
    "        'ssebi': ['pavgb', 'pavgw', 'pextrw', 'pinsrw', 'pmaxsw', 'pmaxub', 'pminsw',\n",
    "                  'pminub', 'pmovmskb',\n",
    "                  'pmulhuw', 'psadbw', 'pshufw', ],\n",
    "        'vmx': ['invept', 'invvpid', 'vmcall', 'vmclear', 'vmfunc', 'vmlaunch', 'vmresume', 'vmptrld',\n",
    "                'vmptrst', 'vmread', 'vmwrite', 'vmxoff', 'vmxon', ]\n",
    "    }\n",
    "    inst = inst.split(' ')\n",
    "    if len(inst) > 1:\n",
    "        inst = inst[1]\n",
    "    else:\n",
    "        inst = inst[0]\n",
    "    if 'int' in inst:\n",
    "        return 'int'\n",
    "    for gr in inst_groups.keys():\n",
    "        if inst in inst_groups[gr]:\n",
    "            return gr\n",
    "    for gr in inst_groups.keys():\n",
    "        for mmc in inst_groups[gr]:\n",
    "            if inst in mmc or mmc in inst:\n",
    "                return gr\n",
    "    return 'other'\n",
    "\n",
    "\n",
    "def fine_disassemble(exe, depth=128000):\n",
    "    main_code = get_main_code_section(exe.sections, exe.OPTIONAL_HEADER.BaseOfCode)\n",
    "    md = Cs(CS_ARCH_X86, CS_MODE_32)\n",
    "    md.detail = True\n",
    "    last_address = 0\n",
    "    last_size = 0\n",
    "    begin = main_code.PointerToRawData\n",
    "    end = begin + main_code.SizeOfRawData\n",
    "    ins_count = 0\n",
    "    size_count = 0\n",
    "    sequence_of_groups = ['begin', ]\n",
    "    while True:\n",
    "        data = exe.get_memory_mapped_image()[begin:end]\n",
    "        for i in md.disasm(data, begin):\n",
    "            group = get_instruction_group(i.mnemonic)\n",
    "            if sequence_of_groups[-1] == group:\n",
    "                sequence_of_groups[-1] = (group, 2)\n",
    "            elif sequence_of_groups[-1][0] == group:\n",
    "                sequence_of_groups[-1] = (group, sequence_of_groups[-1][1] + 1)\n",
    "            else:\n",
    "                sequence_of_groups.append(group)\n",
    "            last_address = int(i.address)\n",
    "            last_size = i.size\n",
    "            ins_count += 1\n",
    "            size_count += last_size\n",
    "        begin = max(int(last_address), begin) + last_size + 1\n",
    "        if begin >= end:\n",
    "            break\n",
    "        if ins_count > depth:\n",
    "            break\n",
    "    return sequence_of_groups\n",
    "\n",
    "\n",
    "def quick_disassemble(path, depth=128000):\n",
    "    try:\n",
    "        exe = pefile.PE(path)\n",
    "        gr = fine_disassemble(exe, depth)\n",
    "        return gr\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_sequence(path):\n",
    "    labels = [\"cdt\", \"udt\", \"sdt\", \"adt\", \"cmpdt\", \"cvt\", \"bai\", \"iai\",\n",
    "              \"dai\", \"fai\", \"fci\", \"sai\", \"li\", \"sri\", \"bii\", \"byi\",\n",
    "              \"cj\", \"uj\", \"int\", \"si\", \"io\", \"flg\", \"seg\", \"misc\", \"sr\",\n",
    "              \"rng\", \"arr\", \"pmi\", \"pci\", \"mmxt\", \"mmxc\", \"mmxa\",\n",
    "              \"mmxcmp\", \"mmxl\", \"mmxsr\", \"mmxsm\", \"sset\", \"ssea\",\n",
    "              \"ssecmp\", \"ssel\", \"ssesu\", \"ssecvt\", \"fdt\", \"ftrdt\", \"flc\",\n",
    "              \"tse\", \"ssebi\", \"vmx\", \"other\"]\n",
    "\n",
    "    labels_array = np.array(labels).reshape(-1, 1)\n",
    "    hot_encoder = OneHotEncoder(sparse=False)\n",
    "    encoded_labels = hot_encoder.fit_transform(labels_array)\n",
    "\n",
    "    encode_dict = {}\n",
    "    for l, e in zip(labels, encoded_labels):\n",
    "        encode_dict[l] = e\n",
    "\n",
    "    count = 0\n",
    "    sequence = quick_disassemble(path)\n",
    "    if sequence is not None:\n",
    "        del sequence[0]\n",
    "        for s in sequence:\n",
    "            if isinstance(s, str):\n",
    "                count += 1\n",
    "            else:\n",
    "                count += s[1]\n",
    "        steps = 128\n",
    "        vect = 49\n",
    "        data_array = np.zeros((int(count / steps) + 1, steps, vect), dtype='float32')\n",
    "        length = steps\n",
    "        i, j, k = (0, 0, 0)\n",
    "        for s in sequence:\n",
    "            if isinstance(s, str):\n",
    "                data_array[i, j] = encode_dict[s] + 0.\n",
    "                j += 1\n",
    "                if j > length - 1:\n",
    "                    j = 0\n",
    "                    i += 1\n",
    "            else:\n",
    "                for _ in range(s[1]):\n",
    "                    data_array[i, j] = encode_dict[s[0]] + 0.\n",
    "                    j += 1\n",
    "                    if j > length - 1:\n",
    "                        j = 0\n",
    "                        i += 1\n",
    "        return data_array\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def extract_img(path, h=64, w=64):\n",
    "    images = []\n",
    "    with open(path, 'rb') as img_set:\n",
    "        img_arr = img_set.read(h * w)\n",
    "        while img_arr:\n",
    "            if img_arr not in images and len(img_arr) == h * w:\n",
    "                images.append(img_arr)\n",
    "            img_arr = img_set.read(h * w)\n",
    "    len_img = len(images)\n",
    "    img_list = np.zeros(shape=(len_img, h, w, 1), dtype=np.uint8)\n",
    "    for j in range(len(images)):\n",
    "        img_list[j, :, :, 0] = np.reshape(list(images[j]), (h, w))\n",
    "    img_list = img_list.astype('float32')\n",
    "    img_list /= 255\n",
    "    return img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_g_encoder(row, columns, col_parts):\n",
    "    basic_name = 'grams_encoder_part_'\n",
    "    encoded = []\n",
    "    for i in range(8):\n",
    "        sub_row = []\n",
    "        #enc = load_model(os.path.join('encoders', basic_name+str(i)+'.h5'))\n",
    "        enc = models[i+4]\n",
    "        for cp in col_parts[i]:\n",
    "            sub_row.append(row[columns.index(cp)])\n",
    "        arr = np.zeros((1, len(sub_row)))\n",
    "        arr[0] = np.array(sub_row)\n",
    "        row_enc = enc.predict(arr)\n",
    "        encoded.append(row_enc[0])\n",
    "    arr_c = np.concatenate(encoded)\n",
    "    arr_enc = np.zeros((1, arr_c.shape[0]))\n",
    "    arr_enc[0] = arr_c\n",
    "    gc.collect()\n",
    "    return arr_enc\n",
    "\n",
    "\n",
    "def evaluate_df_encoder(imports):\n",
    "    #enc = load_model(os.path.join('encoders', 'dllf_encoder_part_0.h5'))\n",
    "    enc = models[12]\n",
    "    arr = np.zeros((1, len(imports)))\n",
    "    arr[0] = np.array(imports)\n",
    "    row_enc = enc.predict(arr)\n",
    "    return row_enc\n",
    "\n",
    "\n",
    "def joined_prediction(cnn, rnn, saeg, saei):\n",
    "    return 0.756\n",
    "\n",
    "\n",
    "def rectification(g_row, imports, sequence, imgs, grams_pre, imp_pre, seq_pre, cnn_pre):\n",
    "    return 0.1228\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_static(paths):\n",
    "    gc.collect()\n",
    "    loaded = []\n",
    "    for path in paths:\n",
    "        loaded.append(load_model(path))\n",
    "    return loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_models = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yato\\Anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:341: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "paths = [os.path.join(core_models, 'cnn64.h5'),\n",
    "         os.path.join(core_models, 'func_dll_fnn.h5'),\n",
    "         os.path.join(core_models, 'grams_fnn_beta_1.h5'),\n",
    "         os.path.join(core_models, 'sequencer.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_0.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_1.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_2.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_3.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_4.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_5.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_6.h5'),\n",
    "        os.path.join('encoders', 'grams_encoder_part_7.h5'),\n",
    "        os.path.join('encoders', 'dllf_encoder_part_0.h5'),\n",
    "        ]\n",
    "models = load_static(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "exe_path = \"D:\\\\DATASETPFE\\\\samples\\\\malware\\\\2019_S1\\\\test\"\n",
    "#exe_path = \"D:\\\\DATASETPFE\\\\samples\\\\legit\\\\newlegit\"\n",
    "exe_list = []\n",
    "for f in listdir(exe_path):\n",
    "    exe_list.append(f)\n",
    "    \n",
    "original_path = \"D:\\\\new_legit_grams.csv\"\n",
    "with open(original_path, 'r') as grms:\n",
    "    csv_reader = csv.reader(grms)\n",
    "    columns = next(csv_reader)\n",
    "del columns[0]\n",
    "del columns[-1]\n",
    "\n",
    "with open(\"D:\\\\benchmark\\\\dlls encoded\\\\Input\\\\dlls_legit.csv\", 'r') as dlls:\n",
    "    csv_reader = csv.reader(dlls)\n",
    "    col_dlls = next(csv_reader)\n",
    "del col_dlls[0]\n",
    "del col_dlls[-1]\n",
    "\n",
    "with open(\"D:\\\\benchmark\\\\functions encoded\\\\Input\\\\functions_legit.csv\", 'r') as func:\n",
    "    csv_reader = csv.reader(func)\n",
    "    col_func = next(csv_reader)\n",
    "del col_func[0]\n",
    "del col_func[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"..\\\\grams encoded\\\\Input\\\\legit_grams_min_max.csv\"\n",
    "with open(path, 'r') as lgm:\n",
    "    csv_reader = csv.reader(lgm)\n",
    "    row = next(csv_reader)\n",
    "    row = next(csv_reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del row[0]\n",
    "del row[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn 0.8614947\n",
      "rnn 0.8819734\n",
      "grm 0.99999714\n",
      "imp 0.81804675\n",
      "---------------------------\n",
      "cnn 0.80465096\n",
      "rnn 0.99631596\n",
      "grm 0.9999938\n",
      "imp 0.91607773\n",
      "---------------------------\n",
      "cnn 0.3593918\n",
      "rnn 0.76451737\n",
      "grm 0.9999945\n",
      "imp 0.08109633\n",
      "---------------------------\n",
      "cnn 0.7208931\n",
      "rnn 0.34044728\n",
      "grm 0.9999931\n",
      "imp 1.4995454e-06\n",
      "---------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-b42813c0bcd5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D:\\\\benchmark\\\\grams encoded\\\\Model\\\\grams_columns_parts.json\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgcp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mcolumns_parts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mencoded_grams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_g_encoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns_parts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_grams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_grams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-43110f7c602f>\u001b[0m in \u001b[0;36mevaluate_g_encoder\u001b[1;34m(row, columns, col_parts)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0menc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcol_parts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m             \u001b[0msub_row\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_row\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for f in exe_list:\n",
    "    freq = grams_extractor(os.path.join(exe_path, f), columns)\n",
    "    grams_freq = grams_rf(freq)\n",
    "    row = grams_row(grams_freq, columns)\n",
    "    norm_row_ = normalized_row(row)\n",
    "    norm_row = []\n",
    "    for nr in norm_row_:\n",
    "        norm_row.append(nr[0])\n",
    "    # ###Imports\n",
    "    imports = extract_imports(os.path.join(exe_path, f), col_dlls, col_func)\n",
    "    # ###disassemble\n",
    "    sequence = extract_sequence(os.path.join(exe_path, f))\n",
    "    # ###images\n",
    "    img_list = extract_img(os.path.join(exe_path, f))\n",
    "    with open(\"D:\\\\benchmark\\\\grams encoded\\\\Model\\\\grams_columns_parts.json\", 'r') as gcp:\n",
    "        columns_parts = json.load(gcp)\n",
    "    encoded_grams = evaluate_g_encoder(row, columns, columns_parts)\n",
    "    mean = np.mean(encoded_grams[0])\n",
    "    for i in range(len(encoded_grams[0])):\n",
    "        if encoded_grams[0][i] < mean*2:\n",
    "            encoded_grams[0][i] = 0.\n",
    "    encoded_imports = evaluate_df_encoder(imports)\n",
    "    gc.collect()\n",
    "    cnn_pre = models[0].predict(img_list)\n",
    "    seq_pre = models[3].predict(sequence)\n",
    "    grams_pre = models[2].predict(encoded_grams)\n",
    "    imp_pre = models[1].predict(encoded_imports)\n",
    "    print('cnn', np.mean(cnn_pre))\n",
    "    print('rnn', np.mean(seq_pre))\n",
    "    print('grm', grams_pre[0][0])\n",
    "    print('imp', imp_pre[0][0])\n",
    "    print('---------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
